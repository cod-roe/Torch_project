# -*- coding: utf-8 -*-
"""exp007__0109.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WkLxMOQPnwD-jyWSrc03dL3qK3uc9GCd

前回:schedulefree使用

0.43-0.45（沿岸エアロゾル）削除して6チャンネル

今回の実験:
スケジューラー戻す（設定は変更）
初期学習と追加学習
初期学習 学習率低め（1e-4）で5回
追加学習 開始学習率lr =1e-3から 5e-4に変更
たぶん最終も
1e-5から5e-6にしたほうがいい気がする

*毎回変更箇所:Config スプレッドシート番号、colabの場合はfile名

##Colab設定
"""

# コンソールに書く
# function ClickConnect(){
#   console.log("60sごとに再接続");
#   document.querySelector("colab-connect-button").click()
# }
# setInterval(ClickConnect,1000*60);

# Googleドライブをマウント
from google.colab import drive
drive.mount('/content/drive/')

!pip install japanize-matplotlib
!pip install signate
# !pip install schedulefree

"""##ライブラリ読み込み"""

# ライブラリ読み込み
# =================================================
import datetime as dt

import gc
import glob
from IPython.display import display
import logging

# import re
import math
import os
import random
import sys
from pathlib import Path
import pickle
from requests import get #colab
import shutil #colab
from tqdm import tqdm_notebook as tqdm
import warnings
# import zipfile


import numpy as np
import pandas as pd
import seaborn as sns
from scipy import ndimage

# 可視化
import matplotlib.pyplot as plt
import japanize_matplotlib

import cv2
from PIL import Image
from skimage import io
# from torchvision.io import read_image

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms
from torchvision.transforms import v2
from torchvision.models import EfficientNet_V2_S_Weights, efficientnet_v2_s
import torch.nn.functional as F
from torch.utils.data import DataLoader,Dataset, WeightedRandomSampler
from torch.optim.lr_scheduler import CosineAnnealingLR


from sklearn.model_selection import train_test_split  # StratifiedKFold , KFold
from sklearn.metrics import (
    confusion_matrix, roc_auc_score, roc_curve,precision_recall_curve, average_precision_score
)  # ,mean_squared_error,accuracy_score

# from schedulefree import RAdamScheduleFree

"""##Configs"""

######################
# set dirs & filename
######################
serial_number = 8  # スプレッドシートAの番号

comp_name = "Satellite"

if 'google.colab' in sys.modules:  # colab環境
    print("google.colab")
    INPUT_PATH = Path("/content")  # 読み込みファイル場所
    # name_notebook = get('http://172.28.0.2:9000/api/sessions').json()[0]['name'] # ノートブック名を取得
    name_notebook = "exp006_2cycle_0107.ipynb"
    DRIVE = f"/content/drive/MyDrive/Python/SIGNATE/{comp_name}"  # このファイルの親(scr)


elif 'kaggle_web_client' in sys.modules:  # kaggle環境
    INPUT_PATH = Path("../input/")

elif 'VSCODE_CWD' in os.environ: # vscode（ローカル）用
    print("vscode")
    INPUT_PATH =  Path(f"../input/{comp_name}")  # 読み込みファイル場所
    abs_path = os.path.abspath(__file__)  # /tmp/work/src/exp/_.py'
    name_notebook = os.path.basename(abs_path) # ノート名を取得
    DRIVE = os.path.dirname(os.getcwd())  # このファイルの親(scr)

#共通
name = os.path.splitext(name_notebook)[0] # 拡張子を除去　filename
OUTPUT = os.path.join(DRIVE, "output")
OUTPUT_EXP = os.path.join(OUTPUT, name)  # logなど情報保存場所
EXP_MODEL = Path(OUTPUT_EXP, "model")  # 学習済みモデル保存

train_dir = INPUT_PATH / "train/" #学習ファイルのフォルダ
pred_sub_dir = INPUT_PATH / "test/" #testファイルのフォルダ

save_path = OUTPUT_EXP + f"/{name}_metrics.pkl" # 保存と読み込みのパス

######################
# ハイパーパラメータの設定
#model_type:efficientnet_v2_s

num_workers = 2  # DataLoader CPU使用量

train_ratio = 0.9
test_ratio = 0.1

batch_size = 256
epochs = 30


# optimizer_type = "RAdam"
lr = 5e-4 # Adam  0.001　SGD 0.005
# weight_decay = 5e-4
# momentum = 0.9

#最終学習率
# scheduler :CosineAnnealingLR
eta_min=1e-5#5e-6

# 不均衡データのために重みをつける
#損失関数に重みをつける
# weights =[total / len(pos), total / len(neg)]　# クラスごとの重みを各クラスのサンプル数に基づいて調整
weights = [23.8050,  1.0438]

"""##学習データダウンロードと解凍"""

#signateAPI用トークンをコピー

# コピー元とコピー先のパスを指定
source_path = '/content/drive/MyDrive/Python/SIGNATE/signate.json'
destination_path = '/root/.signate/signate.json'

# 保存先ディレクトリがない場合は作成
os.makedirs(os.path.dirname(destination_path), exist_ok=True)

# ファイルをコピー
shutil.copy(source_path, destination_path)

print("signate.json copied successfully.")

# ! signate list

#ファイル表示
! signate files --competition-id=263

#ファイル取得
! signate download --competition-id=263 --file-id=224
! signate download --competition-id=263 --file-id=225
! signate download --competition-id=263 --file-id=226
! signate download --competition-id=263 --file-id=231
! signate download --competition-id=263 --file-id=232


# Commented out IPython magic to ensure Python compatibility.
# %ls

!unzip train_1.zip -d /content/
!unzip train_2.zip -d /content/
!unzip train_3.zip -d /content/

"""##関数とクラス定義"""

# Utilities #
# =================================================

#seedの固定
# =================================================

def seed_everything(seed):
    os.environ["PYTHONHASHSEED"] = str(seed)
    random_state = seed
    random.seed(seed)                     # Python標準のランダムシード
    np.random.seed(seed)                  # NumPyのランダムシード
    torch.manual_seed(seed)               # PyTorchのランダムシード（CPU用）
    torch.cuda.manual_seed(seed)          # PyTorchのランダムシード（GPU用）
    torch.cuda.manual_seed_all(seed)      # PyTorchのランダムシード（マルチGPU用）
    torch.backends.cudnn.deterministic = True  # 再現性のための設定
    torch.backends.cudnn.benchmark = False     # 再現性のための設定



# 今の日時
# =================================================
def dt_now():
    jst = dt.timezone(dt.timedelta(hours=9))  # 日本標準時 (UTC+9)
    dt_now = dt.datetime.now(jst)  # 日本時間を指定
    return dt_now

#ログ保存　 stdout と stderr をリダイレクトするクラス
# =================================================
class StreamToLogger:
    def __init__(self, logger, level):
        self.logger = logger
        self.level = level
        self.linebuf = ""

    def write(self, buf):
        for line in buf.rstrip().splitlines():
            self.logger.log(self.level, line.rstrip())

    def flush(self):
        pass


# make dirs
# =================================================
def make_dirs():
    for d in [EXP_MODEL]:
        os.makedirs(d, exist_ok=True)
    print("フォルダ作成完了")

# load img
# =================================================
def load_img(path):
    img_bgr = cv2.imread(path)
    img_rgb = img_bgr[:, :, ::-1]
    # img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

    return img_rgb


# Pickle形式で保存
# =================================================

def save_metrics_pickle(loss_dict, iou_dict, filename="metrics.pkl"):
    data = {"loss": loss_dict, "iou": iou_dict}
    with open(filename, "wb") as f:
        pickle.dump(data, f)
    print(f"Metrics saved to {filename}")

# Pickle形式で読み込み
# =================================================
def load_metrics_pickle(filename=save_path):
    with open(filename, "rb") as f:
        data = pickle.load(f)
    print(f"Metrics loaded from {filename}")
    return data["loss"], data["iou"]

# データのアップデート
def update_metrics(loss_dict, iou_dict, new_loss, new_iou):
    loss_dict['train'].extend(new_loss['train'])
    loss_dict['val'].extend(new_loss['val'])
    iou_dict['train'].extend(new_iou['train'])
    iou_dict['val'].extend(new_iou['val'])



# 可視化関数 (Seaborn使用) lossとmetrics
# =================================================
def plot_metrics_sns(loss_dict, iou_dict,name=name,  output_dir=OUTPUT_EXP):
    epochs = range(1, len(loss_dict["train"]) + 1)

    # DataFrameに変換
    loss_data = pd.DataFrame({
        'Epoch': epochs,
        'Train Loss': loss_dict["train"],
        'Validation Loss': loss_dict["val"]
    })

    iou_data = pd.DataFrame({
        'Epoch': epochs,
        'Train IoU': iou_dict["train"],
        'Validation IoU': iou_dict["val"]
    })

    # Lossのプロット
    plt.figure(figsize=(12, 5))

    # Train/Validation Lossのプロット
    plt.subplot(1, 2, 1)
    sns.lineplot(data=loss_data, x='Epoch', y='Train Loss', label="Train Loss", marker='o')
    sns.lineplot(data=loss_data, x='Epoch', y='Validation Loss', label="Validation Loss", marker='o')
    plt.title("Loss Over Epochs")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    # y軸の範囲を0から0.015に設定
    plt.ylim(0.002, 0.01)

    # IoUのプロット
    plt.subplot(1, 2, 2)
    sns.lineplot(data=iou_data, x='Epoch', y='Train IoU', label="Train IoU", marker='o')
    sns.lineplot(data=iou_data, x='Epoch', y='Validation IoU', label="Validation IoU", marker='o')
    plt.title("IoU Over Epochs")
    plt.xlabel("Epoch")
    plt.ylabel("IoU")

    plt.legend()

    plt.tight_layout()

    # 画像の保存
    plt.savefig(f"{output_dir}/{name}_transition.png", format="png", dpi=300)
    plt.show()

    return plt




# 可視化関数 ヒートマップとROC
# =================================================
def plot_heatmap_roc(cm,true_list, pred_list,name=name,  output_dir=OUTPUT_EXP):
    """true_list, pred_list
    ROC曲線をプロットし、画像として保存する。

    Args:
        similarities (list): 類似度リスト。
        labels (list): ラベルリスト。
        output_path (str): プロット画像の保存パス。
    """
    # ヒートマップの描画
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 2)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Pred_0", "Pred_1"], yticklabels=["True_0", "True_1"])
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.title("Confusion Matrix")

    #ROC Curveの描画
    fpr, tpr, thresholds = roc_curve(true_list, pred_list)
    auc = roc_auc_score(true_list, pred_list)

    plt.subplot(1, 2, 1)
    plt.plot(fpr, tpr, label=f"AUC = {auc:.4f}")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend()
    plt.grid()

    # plt.savefig(OUTPUT_EXP + f"/{name}_roc-curve.png", format="png", dpi=300)  # 画像を保存
    plt.savefig(f"{output_dir}/{name}_heatmap_roc.png", format="png", dpi=300)
    plt.show()


# 可視化関数
# =================================================
def plot_pr(true_list, pred_list):

    # PR曲線の計算
    precision, recall, thresholds = precision_recall_curve(true_list, pred_list)

    # APスコアの計算
    ap_score = average_precision_score(true_list, pred_list)

    pr_data = pd.DataFrame({
        'Precision': precision[:-1],  # 最後の点は使用しない
        'Recall': recall[:-1],
        'Threshold': thresholds
    })

    # Seabornでプロット
    sns.set(style="whitegrid")
    plt.figure(figsize=(8, 6))

    sns.lineplot(data=pr_data, x='Recall', y='Precision', label=f"AP Score = {ap_score:.2f}")
    plt.title("Precision-Recall Curve", fontsize=16)
    plt.xlabel("Recall", fontsize=14)
    plt.ylabel("Precision", fontsize=14)
    plt.legend(fontsize=12)
    plt.show()

    print(f"APスコア: {ap_score}")

    # 閾値の選定例: F1スコアが最大となる閾値を選択
    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)  # F1スコア計算
    best_threshold_idx = f1_scores.argmax()
    best_threshold = thresholds[best_threshold_idx]

    print(f"最適な閾値: {best_threshold}")




def ndvi(file_path, img=None):
    '''
    ndviを算出する

    Parameters
    ---------------------
    file_path : str
        画像が格納されているファイルのパス

    Returns
    ---------------------
    ndvi_img : numpy.ndarray
        ndvi算出後画像
    '''
    # ファイル名を指定して画像を読み込む
    if file_path:
        img = io.imread(file_path)
    r_channel = img[:, :, 3]
    ur_channel = img[:, :, 4]
    ndvi_img = (ur_channel - r_channel) / (ur_channel + r_channel)
    return ndvi_img

"""使用例
ndvi_img = ndvi(file_path=None, img=img)

print(f'最小値: {ndvi_img.min()}')
print(f'最大値: {ndvi_img.max()}')
print(f'平均値: {ndvi_img.mean()}')

ndvi_scaled = ndvi_scaled[:, :, np.newaxis]
ndvi_scaled.shape
#合体
new_img = np.concatenate([img, ndvi_scaled], axis=2)
new_img.shape

"""

#ランダムに[0, 90, 180, 270]のどれかの角度で回転
class RandomSpecificRotation:
    def __init__(self, angles=[0, 90, 180, 270]):
        self.angles = angles

    def __call__(self, img):
        if not isinstance(img, torch.Tensor):
            raise ValueError("Input image must be a PyTorch Tensor.")
        angle = random.choice(self.angles)  # ランダムに角度を選択
        return v2.functional.rotate(img, angle)  # テンソルに回転を適用

#明るさ変更　明るさの変動: 天候、季節、時間帯 3チャンネル
# class AdjustBrightness:
#     # 弱め0.9 ～ 1.1、強め0.7 ～ 1.3で値を調整
#     def __init__(self, brightness_factor_range=(0.8, 1.2)):
#         self.brightness_factor_range = brightness_factor_range

#     def __call__(self, img):
#         factor = random.uniform(*self.brightness_factor_range)
#         return v2.functional.adjust_brightness(img, factor)

# #コントラスト変更　地形や物体の種類、光の反射
# class AdjustContrast:
#     # 弱め0.9 ～ 1.1、強め0.7 ～ 1.3で値を調整
#     def __init__(self, contrast_factor_range=(0.8, 1.2)):
#         self.contrast_factor_range = contrast_factor_range

#     def __call__(self, img):
#         factor = random.uniform(*self.contrast_factor_range)
#         return v2.functional.adjust_contrast(img, factor)

# カスタムColorJitterクラス
class CustomColorJitter:
    def __init__(self, brightness=0.2, contrast=0.3):
        self.color_jitter = v2.ColorJitter(
            brightness=brightness,
            contrast=contrast
            )

    def __call__(self, image):
        # 最初の3チャンネル（RGB）にのみ ColorJitter を適用
        rgb_channels = image[:3]
        transformed_rgb = self.color_jitter(rgb_channels)

        # 残りの4〜7チャンネルはそのまま保持
        remaining_channels = image[3:]

        # 結合して最終的な画像を作成
        return torch.cat((transformed_rgb, remaining_channels), dim=0)

# カスタムクリッピング + 正規化
class ClampNormalize(torch.nn.Module):
    def __init__(self, min_val, max_val):
        super().__init__()
        self.min_val = min_val
        self.max_val = max_val

    def forward(self, img):
        img = torch.clamp(img, min=self.min_val, max=self.max_val)  # クリッピング
        img = (img - self.min_val) / (self.max_val - self.min_val)  # スケーリング
        return img

# 前処理
class ImageTransform:
    '''
    画像の前処理クラス
    学習時と検証時で挙動を変える
    外れ値があるためクリッピング→正規化を最後ではなく最初に行う

    Attributes
    --------------------
    min :
    mean : tupple
        各チャネルの平均値
    std : tupple
        各チャネルの標準偏差
    '''
    def __init__(self, input_size=64):
        self.transforms = {
            'train': v2.Compose([
                v2.ToImage(), # [ H, W, C] 形式 から [C, H, W] 形式とtensor化
                CustomColorJitter(brightness=0.2, contrast=0.2),
                ClampNormalize(min_val=5000, max_val=30000),  # クリッピングと正規化 標準5000~30000
                v2.RandomHorizontalFlip(p=0.5),  # 50%の確率で水平フリップ
                v2.RandomVerticalFlip(p=0.5),    # 50%の確率で垂直フリップ
                RandomSpecificRotation(angles=[0, 90, 180, 270]),  # 0度、90度、180度、270度の回転
                # v2.Pad(padding=4),  # 4ピクセルのパディング
                # v2.RandomCrop(size=(32, 32)),  # 32x32のサイズでランダムにクロッピング
                # v2.RandAugment(3, 9),
                # v2.AugMix(3, 3),
                # v2.Resize((input_size, input_size)),
                #v2.Normalize(mean, std) #標準化
            ]),
            'val': v2.Compose([
                v2.ToImage(), # [ H, W, C] 形式 から [C, H, W] 形式とtensor化
                ClampNormalize(min_val=5000, max_val=30000),  # クリッピングと正規化
                v2.Resize((input_size, input_size)),
                #v2.Normalize(mean, std) #標準化
            ])
        }
    def __call__(self, img, phase='train'):
        return self.transforms[phase](img)

# Dataset
class SatelliteDataset(Dataset):

    def __init__(
        self, dir, file_list, transform=None, phase="train", channel="RGB" , give_label=True):
        """
        Attributes
        -------------------
        dir : str
            画像が保管されているパス
        file_list : dataframe
            画像のファイル名とフラグが格納されているデータフレーム
        transform : torchvision.transforms.Compose
            前処理パイプライン
        phase : str
            学習か検証かを選択
        channel : str
            使用するチャネル(初期値はRGB)
        """
        self.dir = dir
        self.file_list = file_list
        self.transform = transform
        self.phase = phase
        self.image_path = file_list["file_name"].to_list()
        self.image_label = file_list["flag"].to_list()
        self.channel = channel
        self.give_label = give_label


    def __len__(self):
        return len(self.image_path)

    def __getitem__(self, idx):
        # 画像をロード
        img_path = str(Path(self.dir) / self.image_path[idx])
        # img = read_image(self.dir / img_path)  # [C, H, W] 形式　tif対応していない
        if  self.channel == "ALL":
            img = io.imread(img_path)  # [ H, W, C] 形式
        elif  self.channel =="RGB":
            img = io.imread(img_path)[ :, :,[3, 2, 1]]  # [ H, W, C] 形式 # BGR -> RGB
        elif  self.channel =="6c":
            img = io.imread(img_path)[ :, :,[3, 2, 1,4,5,6]]  # [ H, W, C] 形式 # BGR -> RGB

        # 前処理の実装
        if self.transform:
            img = self.transform(img, self.phase)
        label = self.image_label[idx]

        if self.give_label :
            return img, label
        else:
            return img


# モデルの定義
# カスタム画像分類
class EfficientNetS(nn.Module):
    def __init__(self, num_class, final_in_features=1280, input_channels=6):#
        super().__init__()
        # EfficientNetV2-Sの事前学習済みモデルをロード
        base_model = efficientnet_v2_s(pretrained=True)

        # 最初の畳み込み層を取得し、6層にカスタマイズ
        original_conv = base_model.features[0][0]  # 最初のConv2d
        base_model.features[0][0] = nn.Conv2d(
            in_channels=input_channels,  # 入力チャンネル数を7に変更
            out_channels=original_conv.out_channels,
            kernel_size=original_conv.kernel_size,
            stride=original_conv.stride,
            padding=original_conv.padding,
            bias=original_conv.bias is not None,
        )

        # エンコーダ部分
        self.encoder = nn.Sequential(
            base_model.features,
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(1),
        )

        # 分類層
        self.classifier = nn.Sequential(
            nn.Dropout(0.2),
            nn.Linear(final_in_features, num_class),
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.classifier(x)
        return x

# 異常検出のための信頼度スコアの計算
def get_predictions(model, dataloaders_dict):
    model.eval()  # 評価モードに設定
    pred_list = []
    all_confidence_scores = []
    true_list = []

    with torch.no_grad():
        for images, labels in tqdm(dataloaders_dict["train"]):
            images = images.float().to(device)
            labels = labels.to(device)
            outputs = model(images)
            probabilities = F.softmax(outputs, dim=1)
            confidence_scores = probabilities.max(dim=1)[0]  # 最大確率を信頼度スコアとして使用
            predictions = torch.argmax(probabilities, dim=1)

            pred_list.extend(predictions.cpu().numpy())
            all_confidence_scores.extend(confidence_scores.cpu().numpy())
            true_list.extend(labels.to("cpu").numpy())

    cm = confusion_matrix(true_list, pred_list)#.flatten()


    # display(cm)

    # 各要素を分解
    tn, fp, fn, tp = cm.ravel()
    # tn, fp, fn, tp = confusion_matrix(true_list, pred_list).flatten()
    labels = ["TN", "FP", "FN", "TP"]

    #  ヒートマップとROCの描画
    plot_heatmap_roc(cm,true_list, pred_list,name=name,  output_dir=OUTPUT_EXP)

    # 混同行列の表示
    print("Confusion Matrix:")
    plt.bar(labels, [tn, fp, fn, tp], color="skyblue")
    plt.xlabel("Confusion Matrix Elements")
    plt.ylabel("Count")
    plt.title("Confusion Matrix Elements")
    plt.show()


    eval_iou = tp / (tp + fp + fn)
    print(f"eval_IoU: {eval_iou:.4f}")


    return pred_list,true_list, all_confidence_scores




# ラベルの一致確認と異常データの抽出
def detect_anomalies(pred_list,true_list, all_confidence_scores, threshold=0.6):
    all_confidence_scores = np.array(all_confidence_scores, dtype=np.float32)
    pred_list = np.array(pred_list)
    true_list = np.array(true_list)
    # 信頼度スコアがしきい値を下回る場合、または予測がラベルと一致しない場合を異常として検出
    anomalies =  (pred_list != true_list)| (all_confidence_scores < threshold)
    return anomalies

# 学習データのフィルタリング
def filter_clean_data(image_paths, labels, anomalies):
    # DataFrameにしてインデックスを揃えた上でフィルタリング
    data = pd.DataFrame({
        "file_name": image_paths,
        "label": labels,
        "anomaly": anomalies
    })
    # 異常フラグがFalseのデータのみ取得
    clean_data = data[data["anomaly"] == False]
    return clean_data["file_name"].tolist(), clean_data["label"].tolist()

#学習の関数定義
# confusion_matrix版
def train_model(model, start_epoch, stop_epoch,epochs, dataloaders_dict, criterion, optimizer, freeze_backbone=False):
    #  検証時のベストスコアを更新したときに、そのエポック時点のモデルパラメータを保存するようにコーディング。
    best_iou = 0.0
    loss_dict = {"train": [], "val": []}
    iou_dict = {"train": [], "val": []}
    if freeze_backbone:
        # 【初期学習】バックボーンのパラメータを固定
        for param in model.encoder[0].parameters():
            param.requires_grad = False
    elif not freeze_backbone:
            # 【追加学習】バックボーンのパラメータを解凍
        for param in model.encoder[0].parameters():
            param.requires_grad = True

    for epoch in range(start_epoch, stop_epoch):

        print("="*20 + f"Epoch: {epoch+1} / {stop_epoch}(全{epochs})Start!"+"="*20)
        print(f"現在の学習率: {optimizer.param_groups[0]['lr']}" )

        for phase in ["train", "val"]:
            if phase == "train":
                model.train()
                # optimizer.train()
            else:
                model.eval()
                # optimizer.eval()
            epoch_loss = 0.0
            pred_list = []
            true_list = []
            for images, labels in tqdm(dataloaders_dict[phase]):
                images = images.float().to(device, non_blocking=True) # データを非同期的に GPU に転送
                labels = labels.to(device, non_blocking=True)

                optimizer.zero_grad() # 勾配のリセット
                with torch.set_grad_enabled(phase == "train"):
                    with torch.autocast(device_type=device):  # autocastのコンテキスト
                        # 出力
                        outputs = model(images)
                        # 損失計算
                        loss = criterion(outputs, labels)
                        _, preds = torch.max(outputs, 1)
                    if phase == "train":
                        #逆伝播と勾配更新（GradScalerを使用）
                        scaler.scale(loss).backward()
                        scaler.step(optimizer)
                        scaler.update()

                    epoch_loss += loss.item() * images.size(0)
                    preds = preds.to("cpu").numpy()
                    pred_list.extend(preds)
                    labels = labels.to("cpu").numpy()
                    true_list.extend(labels)

            if phase == "train":
                scheduler.step()  # エポック終了時に学習率更新

            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)
            tn, fp, fn, tp = confusion_matrix(true_list, pred_list).flatten()
            epoch_iou = tp / (tp + fp + fn)
            loss_dict[phase].append(epoch_loss)
            iou_dict[phase].append(epoch_iou)
            print(f"{phase}_Loss: {epoch_loss:.5f} {phase}_IoU: {epoch_iou:.4f}")


            #パラメータの保存
            if (phase == "val") and (
                (epoch_iou > best_iou)
                or ((epoch + 1) == epochs)
                or ((epoch + 1) == stop_epoch)
            ):
                best_iou = epoch_iou
                checkpoint_path = (
                    EXP_MODEL / f"{name}_epoch{epoch+1}_iou_{epoch_iou:.4f}.pth"
                )

                # optimizer.eval()#なくてもいい
                torch.save(
                    {
                        "epoch": epoch + 1,
                        "model_state_dict": model.state_dict(),
                        "optimizer_state_dict": optimizer.state_dict(),
                        # "epoch_iou": epoch_iou,
                    },
                    checkpoint_path,
                )
                print(f"Model checkpoint saved at {checkpoint_path}")

    print("well Done!!")
    return loss_dict, iou_dict

# 検証関数（DataLoader使用）
def predict_eval(model, eval_loader):
    eval_loss = 0.0
    pred_list = []
    true_list = []
    model.eval()
    with torch.no_grad():
        for images, labels in tqdm(eval_loader):
            images = images.float().to(device)
            labels = labels.to(device)

            outputs = model(images)
            # 損失計算
            loss = criterion(outputs, labels)
            _, preds = torch.max(outputs, 1)

            eval_loss += loss.item() * images.size(0)
            preds = preds.to("cpu").numpy()
            pred_list.extend(preds)
            labels = labels.to("cpu").numpy()
            true_list.extend(labels)

    epoch_loss = eval_loss / len(eval_loader.dataset)
    cm = confusion_matrix(true_list, pred_list)#.flatten()


    # 各要素を分解
    tn, fp, fn, tp = cm.ravel()
    # tn, fp, fn, tp = confusion_matrix(true_list, pred_list).flatten()
    labels = ["TN", "FP", "FN", "TP"]

    #  ヒートマップとROCの描画
    plot_heatmap_roc(cm,true_list, pred_list,name=name,  output_dir=OUTPUT_EXP)

    # 混同行列の表示
    print("Confusion Matrix:")
    plt.bar(labels, [tn, fp, fn, tp], color="skyblue")
    plt.xlabel("Confusion Matrix Elements")
    plt.ylabel("Count")
    plt.title("Confusion Matrix Elements")
    plt.show()


    eval_iou = tp / (tp + fp + fn)
    print(f"eval_IoU: {eval_iou:.4f}eval_loss:{epoch_loss}")
    return epoch_loss, eval_iou,true_list, pred_list

# DataLoaderを使って推論
def predict_sub(model, pred_sub_loader):
    pred_list = []

    model.eval()
    with torch.no_grad():
        for images in tqdm(pred_sub_loader):
            images = images.float().to(device)

            outputs = model(images)

            _, preds = torch.max(outputs, 1)

            preds = preds.to("cpu").numpy()
            pred_list.extend(preds)

    print("Done!")
    return pred_list

"""##実験開始"""

# set up
# =================================================
# utils
warnings.filterwarnings("ignore")
warnings.simplefilter("ignore")
#!%matplotlib inline

# Seabornスタイル
sns.set(style="whitegrid")

# フォルダの作成
make_dirs()

# utils
# # ログファイルの設定
# logging.basicConfig(
#     filename=OUTPUT_EXP +f"/log_{name}.txt", level=logging.INFO, format="%(message)s"
# )
# # ロガーの作成
# logger = logging.getLogger()

#seedの固定
seed_everything(123)

# デバイスの設定
device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)

weights = torch.tensor(weights).to(device)
print(weights)

# %cd /content/drive/MyDrive/Python/SIGNATE/Satellite/output
# %cd /content

# マスターデータ読み込み
# =================================================
train_master = pd.read_csv(INPUT_PATH /'train_master.tsv', sep='\t')
sample_submit = pd.read_csv(INPUT_PATH /'sample_submit.tsv', sep='\t', header=None)

train_master.head()

pos = train_master.loc[train_master['flag']==1]
neg = train_master.loc[train_master['flag']==0]
print(f'テストデータ件数: {len(sample_submit)}')
print(f'学習データ件数: {len(train_master)}')
print(f'正例件数: {len(pos)}')
print(f'負例件数: {len(neg)}')
print(f'正例割合: {round(len(pos)/len(train_master), 3)}')

# 学習データからランダムで1枚取り出して表示

train_size = len(train_master) #学習データのサイズ
idx = random.randint(0, train_size-1) #0から学習データ数の範囲でランダムで整数を抽出
file = train_master['file_name'][idx] #画像ファイル名
label = train_master['flag'][idx] #画像ラベル

# img_path = f"../input/Satellite/train/{file}"  # 画像が格納されているパス
img_path = INPUT_PATH / f'train/{file}' #画像が格納されているパス


img = io.imread(img_path) #画像を開く
print(f'画像形状: {img.shape}')

# チャネルごとに表示
channel_label = ['1', 'B', 'G', 'R', '5', '6', '7']
print(f'ラベル: {label}')
fig, ax = plt.subplots(nrows=1, ncols=7, figsize=(15, 5))
for i in range(7):
    ax[i].imshow(img[:, :, i])
    ax[i].set_title(channel_label[i])
    ax[i].set_axis_off()
plt.show()

#tifデータの処理の確認
train_size = len(train_master) #学習データのサイズ
idx = random.randint(0, train_size-1) #0から学習データ数の範囲でランダムで整数を抽出
file = train_master['file_name'][idx] #画像ファイル名
label = train_master['flag'][idx] #画像ラベル

# img_path = f"../input/Satellite/train/{file}"  # 画像が格納されているパス VSCode
img_path = INPUT_PATH / f'train/{file}' #画像が格納されているパス

img = io.imread(img_path) #画像を開く

# img = img[ :, :,[3, 2, 1]]  # BGR -> RGB
img = img[  :, :,[3, 2, 1,4,5,6]]  # BGR -> RGB

img = v2.ToImage()(img) # [ H, W, C] 形式 から [C, H, W] 形式とtensor化
print(f'画像形状: {img.shape}')

"""##データ準備
データ分割、前処理、データセット、DataLoaderの作成
"""

#確認テスト: パイプライン

# 入力画像（ダミー）
sample_image = torch.randn(6, 32, 32)

# 変換器の準備
transformer = ImageTransform()

# 学習用前処理
train_image = transformer(sample_image, phase="train")

# バリデーション用前処理
val_image = transformer(sample_image, phase="val")

print(f"学習用画像形状: {train_image.shape}")
print(f"バリデーション用画像形状: {val_image.shape}")

# 学習用、検証用、評価用に分割(8:1:1)

#学習用と評価用に9:1に分ける
train_files, eval_files, train_labels, eval_labels = train_test_split(
    train_master["file_name"],
    train_master["flag"],
    test_size=test_ratio,
    stratify=train_master["flag"],
    random_state=123,
)


#学習用と検証用を（全体の）8:1になるように分ける
train_files, valid_files, train_labels, valid_labels = train_test_split(
    train_files,
    train_labels,
    test_size=test_ratio  / train_ratio,
    stratify=train_labels,
    random_state=123,
)

print(f'学習用データサイズ: {len(train_files)}')
print(f'検証用データサイズ: {len(valid_files)}')
print(f'評価用データサイズ: {len(eval_files)}')
print(f'学習用データ正例比率: {train_labels.mean()}')
print(f'検証用データ正例比率: {valid_labels.mean()}')
print(f'評価用データ正例比率: {eval_labels.mean()}')

train_data = train_master.loc[train_master.index.isin(train_files.index)].reset_index(drop=True)
valid_data = train_master.loc[train_master.index.isin(valid_files.index)].reset_index(drop=True)
eval_data = train_master.loc[train_master.index.isin(eval_files.index)].reset_index(drop=True)

#データセット作成
train_dataset = SatelliteDataset(dir=train_dir, file_list=train_data, transform=ImageTransform(), phase='train', channel='6c')#, channel='RGB'
valid_dataset = SatelliteDataset(dir=train_dir, file_list=valid_data, transform=ImageTransform(), phase='val', channel='6c') #channel='ALL'
eval_dataset = SatelliteDataset(dir=train_dir, file_list=eval_data, transform=ImageTransform(), phase='val', channel="6c")

#確認: それぞれのデータセットからランダムサンプリングを行う
tr_idx = random.randint(0, len(train_dataset))
val_idx = random.randint(0, len(valid_dataset))
eval_idx = random.randint(0, len(eval_dataset))

tr_sample = train_dataset[tr_idx]
val_sample = valid_dataset[val_idx]
eval_sample = eval_dataset[eval_idx]

print(f'学習用データサンプル形状: {tr_sample[0].shape}')
print(f'学習用データサンプルラベル: {tr_sample[1]}')
print(f'検証用データサンプル形状: {val_sample[0].shape}')
print(f'検証用データサンプルラベル: {val_sample[1]}')
print(f'評価用データサンプル形状: {eval_sample[0].shape}')
print(f'評価用データサンプルラベル: {eval_sample[1]}')

#WeightedRandomSampler 損失関数かどちらか
# # torch を使った方法

# # train_master['flag'] からラベルを取得
# labels =  torch.tensor(train_data["flag"].values)

# # 正例と負例の数を取得
# num_samples = len(labels)
# num_positives = torch.sum(labels == 1).item()
# num_negatives = torch.sum(labels == 0).item()

# print(f'学習データ件数: {num_samples}')
# print(f'正例件数: {num_positives}')
# print(f'負例件数: {num_negatives}')
# print(f'正例割合: {round(num_positives/num_samples, 3)}')


# # DataLoaderのsamplerの重み付きランダムサンプリング（WeightedRandomSampler）
# # 重み計算を正例と負例の実際の数に基づいて行う

# # 重みの計算 (正例: desired_ratio, 負例: 1 - desired_ratio)
# desired_ratio = 0.2 # 例: 正例を20%に増やす

# # 正例と負例に対する重みを計算
# weights = torch.where(
#     labels == 1,  # 正例に対する重み
#     desired_ratio / num_positives,
#     (1 - desired_ratio) / num_negatives,
# )

# weights = weights / weights.sum()

# # WeightedRandomSamplerを設定
# sampler = WeightedRandomSampler(
#     weights, num_samples=num_samples, replacement=True
# )

# DataLoaderの作成
# =================================================
# DataLoader
train_dataloader = DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=True,#初期学習時はFalse
    num_workers=num_workers,
    pin_memory=True,
)
valid_dataloader = DataLoader(
    valid_dataset,
    batch_size=batch_size,
    shuffle=False,
    num_workers=num_workers,
    pin_memory=True,
)

dataloaders_dict = {"train": train_dataloader, "val": valid_dataloader}

#確認: データローダーの動作
for inputs, labels in train_dataloader:
    print(inputs.shape, labels.shape)
    break

"""##モデルの準備"""

# model
num_class=2
model =  EfficientNetS(num_class=num_class)

# デバイスの設定
device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)
# デバイスに移動
model = model.to(device)


# weights =[23.8050,  1.0438]
# pos = train_master.loc[train_master['flag']==1]
# neg = train_master.loc[train_master['flag']==0]
# total = len(train_master)
# print(f'学習データ件数: {total}')
# print(f'正例件数: {len(pos)}')
# print(f'負例件数: {len(neg)}')
# print(f'正例割合: {round(len(pos)/len(train_master), 3)}')

# クラスごとの重みを各クラスのサンプル数に基づいて調整
# weights = [total / len(pos), total / len(neg)] #[23.8050,  1.0438]

# PyTorchのテンソルに変換
weights = torch.tensor(weights).to(device)
print(f"weight:{weights}")
print(f"eta_min:{eta_min}")


# learning settings
criterion = nn.CrossEntropyLoss(weights)

optimizer = optim.RAdam(model.parameters(), lr=lr)#, weight_decay=weight_decay
# optimizer = RAdamScheduleFree(model.parameters(), lr=lr, betas=(0.9, 0.999))#1e-4

scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=eta_min)

scaler = torch.cuda.amp.GradScaler()

# モデルの確認
# print(model)



"""##学習開始

###フィルタリング
"""

# #学習パラメータ呼び込み
# last_epoch = 46 #最後のエポック数回数
# epoch_iou = 0.6345
# checkpoint_path =  EXP_MODEL / f"exp005_RAdamScheduleFree_0105_epoch{last_epoch}_iou_{epoch_iou:.4f}.pth"


# checkpoint = torch.load(checkpoint_path) #CPUに読み込み設定 , map_location=torch.device('cpu')
# model.load_state_dict(checkpoint['model_state_dict'])
# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
# start_epoch = checkpoint['epoch']

# # 4. 初期学習と追加学習の統合
# # 異常検出
# predictions,true_list, all_confidence_scores = get_predictions(model=model, dataloaders_dict=dataloaders_dict,)

# print(len(predictions),len(true_list))

# anomalies = detect_anomalies(predictions, true_list, all_confidence_scores)#train_labels

# print(f"異常データの総数: {anomalies.sum()}")  # True の数をカウント

# train_data.head()

# クリーンなデータをフィルタリング
# clean_image_paths, clean_labels = filter_clean_data(train_data['file_name'], train_data['flag'], anomalies)

# train_master_clean = pd.DataFrame({"file_name":clean_image_paths,"flag":clean_labels})
# train_master_clean.head()

#保存初回のみ
# train_master_clean.to_csv(f'{OUTPUT_EXP}/{name}_train_master_clean.tsv', sep='\t')

#読み込み　2回目以降
# train_master_clean = pd.read_csv(f'{OUTPUT_EXP}/{name}_train_master_clean.tsv', sep='\t')
# train_master_clean.columns = ['file_name', 'flag']

# print(f'学習用データサイズ: {len(train_master_clean)}')#233522

# train_master_clean["flag"].mean()#0.04193609167444609

# train_data_clean = train_master.loc[train_master.index.isin(train_master_clean.index)].reset_index(drop=True)

# #データセット作成
# train_dataset_clean = SatelliteDataset(dir=train_dir, file_list=train_data_clean, transform=ImageTransform(), phase='train', channel='6c')#, channel='RGB'

# DataLoaderの作成
# =================================================
# DataLoader
# train_dataloader_clean = DataLoader(
#     train_dataset_clean,
#     batch_size=batch_size,
#     shuffle=True,
#     num_workers=num_workers,
#     pin_memory=True,
# )
# valid_dataloader = DataLoader(
#     valid_dataset,
#     batch_size=batch_size,
#     shuffle=False,
#     num_workers=num_workers,
#     pin_memory=True,
# )

# dataloaders_dict_clean = {"train": train_dataloader_clean, "val": valid_dataloader}

# # model
# num_class=2
# model =  EfficientNetS(num_class=num_class)

# # デバイスの設定
# device = "cuda" if torch.cuda.is_available() else "cpu"
# print(device)
# # デバイスに移動
# model = model.to(device)


# # weights =[23.8050,  1.0438]
# pos_l = train_master_clean.loc[train_master_clean['flag']==1]
# neg_l = train_master_clean.loc[train_master_clean['flag']==0]
# total_l = len(train_master_clean)
# print(f'学習データ件数: {total_l}')
# print(f'正例件数: {len(pos_l)}')
# print(f'負例件数: {len(neg_l)}')
# print(f'正例割合: {round(len(pos_l)/total_l, 3)}')

# # クラスごとの重みを各クラスのサンプル数に基づいて調整
# weights = [total_l / len(pos_l), total_l / len(neg_l)] #[23.8050,  1.0438]

# # PyTorchのテンソルに変換
# weights = torch.tensor(weights).to(device)
# print(f"weight:{weights}")
# print(f"eta_min:{eta_min}")


# # learning settings
# criterion = nn.CrossEntropyLoss(weights)

# optimizer = optim.RAdam(model.parameters(), lr=1e-4)#, weight_decay=weight_decay
# # optimizer = RAdamScheduleFree(model.parameters(), lr=lr, betas=(0.9, 0.999))#1e-4

# scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=eta_min)

# scaler = torch.cuda.amp.GradScaler()

"""###学習1回目(初期学習)"""

# 初期学習
start_epoch = 0
stop_epoch = 5

loss_dict, iou_dict = train_model(
    model=model,
    start_epoch=start_epoch,
    stop_epoch=stop_epoch,
    epochs=epochs,
    dataloaders_dict=dataloaders_dict_clean,
    criterion=criterion,
    optimizer=optimizer,
    freeze_backbone=False
)

# Pickle形式で保存
save_metrics_pickle(loss_dict, iou_dict, save_path)

print(f"loss:{len(loss_dict)}")
print(loss_dict)
print(f"Iou:{len(iou_dict)}")
print(iou_dict)

#可視化 Loss Iou
plot_metrics_sns(loss_dict, iou_dict)

# 終了時刻
print(dt_now().strftime("%Y年%m月%d日 %H:%M:%S"))

"""###追加学習1回目"""

# model
num_class=2
model =  EfficientNetS(num_class=num_class)

# デバイスの設定
device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)
# デバイスに移動
model = model.to(device)


# クラスごとの重みを各クラスのサンプル数に基づいて調整

# PyTorchのテンソルに変換
weights = torch.tensor(weights).to(device)
print(f"weight:{weights}")
print(f"eta_min:{eta_min}")

# learning settings
criterion = nn.CrossEntropyLoss(weights)

optimizer = optim.RAdam(model.parameters(), lr=lr)#, weight_decay=weight_decay
# optimizer = RAdamScheduleFree(model.parameters(), lr=lr, betas=(0.9, 0.999))#1e-4

scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=eta_min)

scaler = torch.cuda.amp.GradScaler()

# 保存したパラメータの読み込み
last_epoch = 5 #最後のエポック数回数
epoch_iou =  0.0000
checkpoint_path =  EXP_MODEL / f"{name}_epoch{last_epoch}_iou_{epoch_iou:.4f}.pth"
checkpoint = torch.load(checkpoint_path)

model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
start_epoch = checkpoint['epoch']

# CosineAnnealingLR の再設定
scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=eta_min, last_epoch=start_epoch -1)

# start_epoch = 5
print(f"Resuming from epoch {start_epoch} ")

#再設定が必要？
optimizer = optim.RAdam(model.parameters(), lr=lr)#, weight_decay=weight_decay
scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=eta_min)#

# モデルの学習　5~10

stop_epoch = 10

new_loss_dict, new_iou_dict = train_model(
    model=model,
    start_epoch=start_epoch,
    stop_epoch=stop_epoch,
    epochs=epochs,
    dataloaders_dict=dataloaders_dict,
    criterion=criterion,
    optimizer=optimizer,
    freeze_backbone=False
)

# lossとmatricsの保存

#呼び出し
loss_dict, iou_dict = load_metrics_pickle(save_path)

#アップデート
update_metrics(loss_dict, iou_dict, new_loss_dict, new_iou_dict)

print(f"loss:{len(loss_dict)}")
print(loss_dict)
print(f"Iou:{len(iou_dict)}")
print(iou_dict)

#保存
save_metrics_pickle(loss_dict, iou_dict, save_path)

#可視化 Loss Iou
plot_metrics_sns(loss_dict, iou_dict)

# 終了時刻
print(dt_now().strftime("%Y年%m月%d日 %H:%M:%S"))

"""###追加学習2回目"""

# model
num_class=2
model =  EfficientNetS(num_class=num_class)

# デバイスの設定
device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)
# デバイスに移動
model = model.to(device)


# クラスごとの重みを各クラスのサンプル数に基づいて調整

# PyTorchのテンソルに変換
weights = torch.tensor(weights).to(device)
print(f"weight:{weights}")
print(f"eta_min:{eta_min}")


# learning settings
criterion = nn.CrossEntropyLoss(weights)

optimizer = optim.RAdam(model.parameters(), lr=lr)#, weight_decay=weight_decay
# optimizer = RAdamScheduleFree(model.parameters(), lr=lr, betas=(0.9, 0.999))#1e-4

scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=eta_min)

scaler = torch.cuda.amp.GradScaler()

# 保存したパラメータの読み込み
last_epoch = 10 #最後のエポック数回数
epoch_iou = 0.5068
checkpoint_path =  EXP_MODEL / f"{name}_epoch{last_epoch}_iou_{epoch_iou:.4f}.pth"
checkpoint = torch.load(checkpoint_path)

model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
start_epoch = checkpoint['epoch']

# CosineAnnealingLR の再設定
scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=eta_min, last_epoch=start_epoch -1)

# start_epoch = 5
print(f"Resuming from epoch {start_epoch} ")

# モデルの学習
stop_epoch = 20

new_loss_dict, new_iou_dict = train_model(
    model=model,
    start_epoch=start_epoch,
    stop_epoch=stop_epoch,
    epochs=epochs,
    dataloaders_dict=dataloaders_dict,
    criterion=criterion,
    optimizer=optimizer,
    freeze_backbone=False
)

# lossとmatricsの保存

#呼び出し
loss_dict, iou_dict = load_metrics_pickle(save_path)
#アップデート
update_metrics(loss_dict, iou_dict, new_loss_dict, new_iou_dict)

print(f"loss:{len(loss_dict)}")
print(loss_dict)
print(f"Iou:{len(iou_dict)}")
print(iou_dict)

#保存
save_metrics_pickle(loss_dict, iou_dict, save_path)

#可視化 Loss Iou
plot_metrics_sns(loss_dict, iou_dict)

# 終了時刻
print(dt_now().strftime("%Y年%m月%d日 %H:%M:%S"))

"""###追加学習3回目"""

# model
num_class=2
model =  EfficientNetS(num_class=num_class)

# デバイスの設定
device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)
# デバイスに移動
model = model.to(device)


# weights =[23.8050,  1.0438]
print(f"weight:{weights}")
print(f"eta_min:{eta_min}")

# learning settings
criterion = nn.CrossEntropyLoss(weights)
optimizer = optim.RAdam(model.parameters(), lr=lr)#, weight_decay=weight_decay

scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=eta_min) #学習率の変化
scaler = torch.cuda.amp.GradScaler()

# 保存したパラメータの読み込み
last_epoch = 20 #最後のエポック数回数
epoch_iou =0.6446
checkpoint_path =  EXP_MODEL / f"{name}_epoch{last_epoch}_iou_{epoch_iou:.4f}.pth"
checkpoint = torch.load(checkpoint_path)

model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
start_epoch = checkpoint['epoch']

# CosineAnnealingLR の再設定
scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=eta_min, last_epoch=start_epoch -1)


# start_epoch = 5
print(f"Resuming from epoch {start_epoch} ")

# モデルの学習
stop_epoch = 25

new_loss_dict, new_iou_dict = train_model(
    model=model,
    start_epoch=start_epoch,
    stop_epoch=stop_epoch,
    epochs=epochs,
    dataloaders_dict=dataloaders_dict,
    criterion=criterion,
    optimizer=optimizer,
    freeze_backbone=False
)

# lossとmatricsの保存

#呼び出し
loss_dict, iou_dict = load_metrics_pickle(save_path)

#アップデート
update_metrics(loss_dict, iou_dict, new_loss_dict, new_iou_dict)

print(f"loss:{len(loss_dict)}")
print(loss_dict)
print(f"Iou:{len(iou_dict)}")
print(iou_dict)

#保存
save_metrics_pickle(loss_dict, iou_dict, save_path)

#可視化 Loss Iou
plot_metrics_sns(loss_dict, iou_dict)

# 終了時刻
print(dt_now().strftime("%Y年%m月%d日 %H:%M:%S"))

"""###追加学習4回目

"""

#新たに設定しなおすとき
# epochs = 25
# # 最適化アルゴリズム : RAdam
# lr = 1e-5  # Adam  0.001　SGD 0.005
# # weight_decay = 5e-4
# # momentum = 0.9

# #最終学習率
# # scheduler :CosineAnnealingLR
# eta_min=5e-6

# model
num_class=2
model =  EfficientNetS(num_class=num_class)

# デバイスの設定
device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)
# デバイスに移動
model = model.to(device)

# weights =[23.8050,  1.0438]
print(f"weight:{weights}")
print(f"eta_min:{eta_min}")


# learning settings
criterion = nn.CrossEntropyLoss(weights)
optimizer = optim.RAdam(model.parameters(), lr=lr)#, weight_decay=weight_decay


scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=eta_min) #学習率の変化
scaler = torch.cuda.amp.GradScaler()

# 保存したパラメータの読み込み
last_epoch = 25 #最後のエポック数回数
epoch_iou =0.6619
checkpoint_path =  EXP_MODEL / f"{name}_epoch{last_epoch}_iou_{epoch_iou:.4f}.pth"
checkpoint = torch.load(checkpoint_path)

model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
start_epoch = checkpoint['epoch']

# CosineAnnealingLR の再設定
scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=eta_min, last_epoch=start_epoch -1)


# start_epoch = 5
print(f"Resuming from epoch {start_epoch} ")

# モデルの学習
stop_epoch = 30

new_loss_dict, new_iou_dict = train_model(
    model=model,
    start_epoch=start_epoch,
    stop_epoch=stop_epoch,
    epochs=epochs,
    dataloaders_dict=dataloaders_dict,
    criterion=criterion,
    optimizer=optimizer,
    freeze_backbone=False
)

# lossとmatricsの保存

#呼び出し
loss_dict, iou_dict = load_metrics_pickle(save_path)

#アップデート
update_metrics(loss_dict, iou_dict, new_loss_dict, new_iou_dict)

print(f"loss:{len(loss_dict)}")
print(loss_dict)
print(f"Iou:{len(iou_dict)}")
print(iou_dict)

#保存
save_metrics_pickle(loss_dict, iou_dict, save_path)

#可視化 Loss Iou
plot_metrics_sns(loss_dict, iou_dict)

# 終了時刻
print(dt_now().strftime("%Y年%m月%d日 %H:%M:%S"))

"""##検証フェーズ"""

# model
num_class=2
model =  EfficientNetS(num_class=num_class)

# デバイスの設定
device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)
# デバイスに移動
model = model.to(device)

# クラスごとの重みを各クラスのサンプル数に基づいて調整
# weights =[23.8050,  1.0438]
print(f"weight:{weights}")
print(f"eta_min:{eta_min}")

# learning settings
criterion = nn.CrossEntropyLoss(weights)
optimizer = optim.RAdam(model.parameters(), lr=lr)#, weight_decay=weight_decay


# scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=eta_min) #学習率の変化
# scaler = torch.cuda.amp.GradScaler()

#学習パラメータ呼び込み
last_epoch = 30 #最後のエポック数回数
epoch_iou = 0.6919
checkpoint_path =  EXP_MODEL / f"{name}_epoch{last_epoch}_iou_{epoch_iou:.4f}.pth"
checkpoint = torch.load(checkpoint_path) #CPUに読み込み設定 , map_location=torch.device('cpu')

model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
start_epoch = checkpoint['epoch']
# start_epoch = 5

# DataLoaderを使って検証
eval_loader = DataLoader(
    eval_dataset,
    batch_size=batch_size,
    shuffle=False,
    num_workers=num_workers,
    pin_memory=True,
)

epoch_loss, eval_iou,true_list, pred_list = predict_eval(model=model, eval_loader=eval_loader)

# PR,AP可視化
plot_pr(true_list, pred_list)

"""##推論フェーズ"""

# 容量に空きを作るためフォルダ削除
shutil.rmtree('/content/train')


#テストファイルダウンロード
! signate download --competition-id=263 --file-id=227
! signate download --competition-id=263 --file-id=228
! signate download --competition-id=263 --file-id=229
! signate download --competition-id=263 --file-id=230
# ! signate download --competition-id=263 --file-id=233

#解凍
!unzip test_1.zip -d /content/
!unzip test_2.zip -d /content/
!unzip test_3.zip -d /content/
!unzip test_4.zip -d /content/

# 提出形式を確認
sample_submit.columns = ['file_name', 'flag']
sample_submit.head()

# DataLoaderを使って推論


pred_sub_data = sample_submit.reset_index(drop=True)


pred_sub_dataset = SatelliteDataset(
    dir=pred_sub_dir,
    file_list=pred_sub_data,
    transform=ImageTransform(),
    phase="val",
    channel='6c',
    give_label=False
)

pred_sub_loader = DataLoader(
    pred_sub_dataset,
    batch_size=batch_size,
    shuffle=False,
    num_workers=num_workers,
    pin_memory=True,
)

# 推論
prediction = predict_sub(model = model,pred_sub_loader=pred_sub_loader)

"""提出ファイル出力"""

file_name = sample_submit['file_name'].values
submit_df = pd.DataFrame(data=[[f, pred] for f, pred in zip(file_name, prediction)])
submit_df.to_csv(f'{OUTPUT_EXP}/{name}_sub30.tsv', sep='\t', header=None, index=None)

submit_df.head()

#APIで提出
# ! signate submit --competition-id=263 /content/drive/MyDrive/Python/SIGNATE/Satellite/output/exp006_2cycle_0107/exp006_2cycle_0107_sub30.tsv --note 初期学習と追加学習

